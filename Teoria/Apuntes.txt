16/8
### REPASO CLASE 14/8

DATASET=MATRIZ

ERROR=LOSS FUNCTION


RIPSHAPE(PARA TRANFORMAR EL VECTOR DE LATERAL  COMO LO QUIERA LA MATRIUZ)


MSE(MEAN SQUARED ERROR)

ERROR(BETA)

B=(Xt.X a la -1)a la -1 .Xt.Y


#REGRESIÓN LOGÍSTICA

ES UNA VARIACIÓN DE LA REGRESIÓN LINEAL

F(X)=1: 1+E a la -(B0+B1.X)

e=2,7182.....
 
UMBRAL=LA MITAD ENTRE O Y 1(MODIFICABLE(PUEDE SER 0,75))

ACCURENCY= CUANTAS ERAN 1 Y DIJE 1 Y CUANTAS ERAN 0 Y DIJE 0:N

TOTAL=(Tn+Tp+Fp+Fn)
__________________________________________________________________________________________________________________________

28/8

Arboles de Decisión
Grafico de clasificacion
Permite hacer cortes en el grafico para clasificar. Devuelve la clase de mayor proporción.

Grafico de regresion
Para hacer la prediccion se hacen los cortes y se Devuelve el promedio

Si tenes muchos cortes va haber Overfiting

Tiene que haber siempre menos Hojas que muestras

(Hojas serían las preguntas (si X2 >3)Si->rojo/no->azul)

La altura del arbol= Cant preguntas

Para empezar haces todos los corteds posibles y te vas a quedar con el menor ERROR usando MSE

Cuando hay un dato muy diferente se lo llama Outlier.

Label Encoding 

Es pasar una columna categorica a numerica, tiene ventajas y deventajas.

One Hot Encoding seria que por cada valor categorico se lo define por booleano en caso de que si sea 1 en caso de que no 0
__________________________________________________________________________________________________________________________


30/9
Practica

__________________________________________________________________________________________________________________________

4/9

###Validacion

DATASET=(X,Y) MATRIZ[x1,x2,xN][y1,y2,yN](La N seria el largo, y la cantidad de X o Y que hay)
X=Variables Predictoras

f¬(x)=y
Se entrena con X train,Y train 
C:MSE
Para ver la performance del grafico agarramos el DATASETy lo partimos en Train y Test.
Costo(f¬(Xtest,YTest))

###Estrategia de Validación(Tema Nuevo de hoy)

(Hiper parametros)
Max-depth
min-learn-split
min-child-weight
3estrategias

1. Tengo todo el DATASET y dividimos en Train Test y Validacion
    1ra estrategia Holdout Set
        se compara F1¬ co Validacion en caso de que sean 3f se hace con los tres y te quedas con el más preciso.
        El más preciso seria el que tiene mejores hiperParametros para Validacion
            2da estrategia Cross Validacion(Leave one out)
                Va a agarrar un solo dato y lo deja afuera agarra todos menos uno para entrenar. 
                Agarro F1¬ y comparo con val1 C(F1¬,val1)despues van a quedar 2 datos menos que el otro seria val2 y asi 
                y va a validar con el dato agregado y el otro que se uso para validar queda para entrenar 
                C(F1¬,N train)
                    3ra Estrategia K-Fold
                        dividimosel DATASET en cuato folds quieras
                        Tengo 80 datos, los “foldeo” 4 veces, tengo 4 secciones de 20 datos.
                        Cada fold es un conjunto, el modelo son K valores.
                        En este caso, K es 4, ya que tengo 4 folds.
                        Cada conjunto se utiliza 1 vez para validar.
                        Comparado a el modelo leave one out, este es mucho mas simplificante, ya que con este se valida K
                        veces y con el otro se valida la cantidad de veces como cuantos datos tengas en el modelo (Ej: 79 veces)
__________________________________________________________________________________________________________________________

6/9

###Ensambles

Metodo BootStrap


Ensamblar= Unir modelos

Vamos a poner a entrenar los ensambles con distintas partes dell conjunto de Train.

Lo que va hacer este Metodo es que teniendo un dataset de Xp de ancho y Xn de largo y devuelven valores Y hasta N

A todo este conjunto de trains lo vamos a llamar Z.

Z0 va a mustrear un valor por ejemplo [X3,Y3],[X1,Y1][X3,Y3] Cunado elige de nuevo se llama samplear con reposición.

 1er Formato de Ensable
    Bagagging
        BootStrap Agregating. F0¬,F1¬,F2¬. Todos estos los voy a usar para predecir (Falta explicar)
2do
    Random Forest
        (No Anote)
3er
    Boosting
        (No Anote)
__________________________________________________________________________________________________________________________

13/9

TruePositive=TP
TrueNegative=TN
FalsePositive=FP
FalseNegative=FN

Precision=TP/TP+FP 
Recall=TP/TP+FN 
Recall llamdo TPR (True positive Rate)

También existe el FPR que seria lo contrario a TPR

__________________________________________________________________________________________________________________________

18/9

